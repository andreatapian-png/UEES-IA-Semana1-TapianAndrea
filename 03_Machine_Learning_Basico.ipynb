{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlRV30wq2K_v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f306138"
      },
      "source": [
        "# Task\n",
        "Create a comprehensive tutorial on classification and regression models using Scikit-learn, covering theoretical foundations, practical implementation with data loading and preprocessing, model training, prediction, evaluation metrics, and comparison of different algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba40f35b"
      },
      "source": [
        "## Introducción a Modelos de Clasificación\n",
        "\n",
        "### Subtask:\n",
        "Explicar los fundamentos de los modelos de clasificación, sus tipos y casos de uso comunes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "930bd1ff"
      },
      "source": [
        "### 1. Introducción a los Modelos de Clasificación\n",
        "\n",
        "Los **modelos de clasificación** son una categoría fundamental dentro del aprendizaje automático supervisado, cuyo objetivo principal es predecir la categoría o clase a la que pertenece un elemento dado, basándose en un conjunto de características de entrada. A diferencia de los problemas de regresión, donde se predice un valor continuo (por ejemplo, el precio de una casa), en la clasificación se predice un valor discreto (por ejemplo, si un correo electrónico es spam o no, o si una imagen contiene un perro o un gato).\n",
        "\n",
        "La distinción clave radica en la naturaleza de la salida. Mientras que la regresión busca modelar la relación entre variables para predecir un número, la clasificación se enfoca en aprender patrones para asignar etiquetas categóricas. Esto los hace herramientas poderosas para tomar decisiones y organizar datos en un sinfín de aplicaciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70b47c63"
      },
      "source": [
        "### 2. Tipos Comunes de Modelos de Clasificación\n",
        "\n",
        "Los problemas de clasificación se pueden categorizar en diferentes tipos, dependiendo del número de clases y cómo se relacionan entre sí:\n",
        "\n",
        "*   **Clasificación Binaria:** Este es el tipo más simple de clasificación, donde el modelo predice entre dos clases posibles. Por ejemplo, clasificar un correo electr\\u00f3nico como 'spam' o 'no spam', o determinar si una transacci\\u00f3n financiera es 'fraudulenta' o 'no fraudulenta'.\n",
        "\n",
        "*   **Clasificación Multiclase:** En este escenario, el modelo debe asignar una instancia a una de m\\u00faltiple clases exclusivas. Es decir, una instancia solo puede pertenecer a una \\u00fanica clase de un conjunto de tres o m\\u00e1s clases. Ejemplos incluyen el reconocimiento de d\\u00edgitos escritos a mano (donde cada d\\u00edgito 0-9 es una clase) o la clasificaci\\u00f3n de tipos de flores (iris Setosa, Versicolor, Virginica).\n",
        "\n",
        "*   **Clasificación Multietiqueta (Multi-label Classification):** A diferencia de la clasificaci\\u00f3n multiclase, aqu\\u00ed una instancia puede pertenecer a m\\u00faltiple clases simult\\u00e1neamente. Por ejemplo, una pel\\u00edcula puede ser categorizada como 'Acci\\u00f3n', 'Aventura' y 'Ciencia Ficci\\u00f3n' al mismo tiempo. Otro ejemplo podr\\u00eda ser la clasificaci\\u00f3n de g\\u00e9neros musicales de una canci\\u00f3n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd7f0804"
      },
      "source": [
        "### 3. Casos de Uso Comunes de los Modelos de Clasificación\n",
        "\n",
        "Los modelos de clasificación se aplican en una vasta gama de industrias y problemas. Algunos de los casos de uso más comunes incluyen:\n",
        "\n",
        "*   **Detección de Spam:** Clasificar correos electrónicos como 'spam' o 'no spam' para proteger a los usuarios de contenido no deseado. Esto es un ejemplo clásico de clasificación binaria.\n",
        "\n",
        "*   **Diagnóstico Médico:** Identificar la presencia o ausencia de una enfermedad basándose en síntomas, resultados de pruebas o imágenes médicas. Por ejemplo, clasificar una imagen de resonancia magnética como 'tumor benigno', 'tumor maligno' o 'sin tumor' (multiclase).\n",
        "\n",
        "*   **Reconocimiento de Imágenes y Visión por Computadora:** Clasificar objetos dentro de imágenes o videos, como identificar diferentes tipos de animales, vehículos, o reconocer rostros. También se usa para etiquetado automático de imágenes (multiclase o multietiqueta).\n",
        "\n",
        "*   **Análisis de Sentimiento:** Determinar la polaridad del sentimiento expresado en un texto (positivo, negativo, neutro) en reseñas de productos, comentarios en redes sociales o artículos de noticias.\n",
        "\n",
        "*   **Detección de Fraude:** Identificar transacciones financieras sospechosas o actividades fraudulentas en sistemas bancarios, seguros o comercio electrónico (clasificación binaria).\n",
        "\n",
        "*   **Recomendación de Productos:** Clasificar la probabilidad de que un usuario esté interesado en un producto o servicio basándose en su historial de compras y navegación, para ofrecer recomendaciones personalizadas.\n",
        "\n",
        "*   **Clasificación de Documentos:** Organizar documentos en categorías predefinidas, como artículos de noticias por tema (deportes, política, tecnología) o documentos legales por tipo.\n",
        "\n",
        "*   **Predicción de Churn (abandono de clientes):** Identificar a los clientes que tienen una alta probabilidad de dejar de usar un servicio o producto, permitiendo a las empresas tomar medidas preventivas.\n",
        "\n",
        "Estos ejemplos demuestran la versatilidad y el impacto significativo que los modelos de clasificación tienen en la resolución de problemas del mundo real."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "488dc3e1"
      },
      "source": [
        "## Implementación de Modelos de Clasificación con Scikit-learn\n",
        "\n",
        "### Subtask:\n",
        "Demostrar la implementación de un modelo de clasificación usando Scikit-learn, incluyendo la carga de datos, preprocesamiento, entrenamiento del modelo y predicción. Se incluirá un ejemplo práctico.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5884419"
      },
      "source": [
        "**Reasoning**:\n",
        "The first step in the subtask is to load the Iris dataset from `sklearn.datasets`. This will provide the data needed for the classification example.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d54f347"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "print(\"Keys of iris_dataset:\\n{}\".format(iris.keys()))\n",
        "print(iris['DESCR'][:193] + \"\\n...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fd8dbb8"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the instructions, the next step is to split the dataset into training and testing sets, initialize a Logistic Regression model, train it, make predictions, and finally evaluate its accuracy. All these steps are part of the practical implementation of a classification model using Scikit-learn.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "1e0c7800",
        "outputId": "7541e86e-a2b9-4ad7-d834-3511c170e77c"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 2. Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Tamaño del conjunto de entrenamiento (X_train): {X_train.shape}\")\n",
        "print(f\"Tamaño del conjunto de prueba (X_test): {X_test.shape}\")\n",
        "\n",
        "# 3. Inicializar un modelo de clasificación (Logistic Regression)\n",
        "# Se establece random_state para reproducibilidad y max_iter para evitar advertencias de convergencia.\n",
        "model = LogisticRegression(random_state=42, max_iter=200)\n",
        "\n",
        "# 4. Entrenar el modelo con los datos de entrenamiento\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Realizar predicciones sobre el conjunto de datos de prueba\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 6. Calcular e imprimir la precisión (accuracy) del modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Precisión del modelo de Regresión Logística: {accuracy:.4f}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2083172885.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 2. Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Tamaño del conjunto de entrenamiento (X_train): {X_train.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f30b3c26"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed because `X` and `y` were not defined, indicating that the data loading step was not executed. To fix this, I will combine the data loading and assignment of `X` and `y` from the earlier cell into this cell to ensure all necessary variables are available before proceeding with `train_test_split` and model training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b78cbe6",
        "outputId": "c51a75bf-5842-494f-eab3-ed050a28d0d0"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Cargue el conjunto de datos Iris\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "print(\"Keys of iris_dataset:\\n{}\".format(iris.keys()))\n",
        "print(iris['DESCR'][:193] + \"\\n...\")\n",
        "\n",
        "# 2. Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Tamaño del conjunto de entrenamiento (X_train): {X_train.shape}\")\n",
        "print(f\"Tamaño del conjunto de prueba (X_test): {X_test.shape}\")\n",
        "\n",
        "# 3. Inicializar un modelo de clasificación (Logistic Regression)\n",
        "# Se establece random_state para reproducibilidad y max_iter para evitar advertencias de convergencia.\n",
        "model = LogisticRegression(random_state=42, max_iter=200)\n",
        "\n",
        "# 4. Entrenar el modelo con los datos de entrenamiento\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Realizar predicciones sobre el conjunto de datos de prueba\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 6. Calcular e imprimir la precisión (accuracy) del modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Precisión del modelo de Regresión Logística: {accuracy:.4f}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys of iris_dataset:\n",
            "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            ":Number of Instances: 150 (50 in each of three classes)\n",
            ":Number of Attributes: 4 numeric, predictive \n",
            "...\n",
            "Tamaño del conjunto de entrenamiento (X_train): (105, 4)\n",
            "Tamaño del conjunto de prueba (X_test): (45, 4)\n",
            "Precisión del modelo de Regresión Logística: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c984ed5"
      },
      "source": [
        "## Introducción a Modelos de Regresión\n",
        "\n",
        "### Subtask:\n",
        "Explicar los fundamentos de los modelos de regresión, sus tipos y casos de uso comunes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a3be353"
      },
      "source": [
        "### 1. Introducción a los Modelos de Regresión\n",
        "\n",
        "Los **modelos de regresión** son una categoría esencial dentro del aprendizaje automático supervisado, cuyo objetivo principal es predecir un **valor continuo o numérico**. A diferencia de los modelos de clasificación, que predicen una categoría o clase discreta (como 'spam' o 'no spam'), los modelos de regresión se enfocan en estimar un resultado que puede tomar cualquier valor dentro de un rango determinado (como el precio de una casa, la temperatura, o la cantidad de ventas).\n",
        "\n",
        "La distinción fundamental radica en la naturaleza de la variable de salida (también conocida como variable dependiente o objetivo):\n",
        "\n",
        "*   **Clasificación:** La variable de salida es **categórica** o **discreta**.\n",
        "*   **Regresión:** La variable de salida es **continua** o **numérica**.\n",
        "\n",
        "El propósito de la regresión es modelar la relación entre una variable dependiente y una o más variables independientes (o predictoras) para poder hacer predicciones sobre nuevos datos. Esto implica encontrar una función que mejor se ajuste a los datos existentes y que pueda extrapolarse para predecir resultados futuros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8c435d3"
      },
      "source": [
        "### 2. Tipos Comunes de Modelos de Regresión\n",
        "\n",
        "Existen diversos algoritmos y enfoques para los modelos de regresión, cada uno con sus propias fortalezas y casos de uso. Algunos de los tipos más comunes incluyen:\n",
        "\n",
        "*   **Regresión Lineal Simple:** Es el modelo de regresión más básico, donde se modela la relación entre una variable independiente y una variable dependiente como una línea recta. Se utiliza cuando se asume una relación lineal entre las dos variables.\n",
        "\n",
        "*   **Regresión Lineal Múltiple:** Una extensión de la regresión lineal simple, donde se modela la relación entre una variable dependiente y dos o más variables independientes utilizando una ecuación lineal. Es útil cuando m\\u00faltiple factores influyen en la variable a predecir.\n",
        "\n",
        "*   **Regresión Polinomial:** Permite modelar relaciones no lineales entre la variable independiente y la dependiente. En lugar de una línea recta, ajusta una curva polinomial a los datos, lo que puede capturar patrones m\\u00e1s complejos.\n",
        "\n",
        "*   **Regresión Ridge y Lasso (Regresión Regularizada):** Estas son extensiones de la regresión lineal que incluyen t\\u00e9rminos de regularizaci\\u00f3n para evitar el sobreajuste (overfitting), especialmente cuando hay muchas variables predictoras o cuando algunas de ellas est\\u00e1n altamente correlacionadas. Ridge a\\u00f1ade un t\\u00e9rmino L2, mientras que Lasso a\\u00f1ade un t\\u00e9rmino L1 que puede llevar a la selecci\\u00f3n de caracter\\u00edsticas al reducir los coeficientes de algunas variables a cero.\n",
        "\n",
        "*   **Regresión de Soporte Vectorial (SVR):** Basada en el concepto de M\\u00e1quinas de Vectores de Soporte, SVR busca una funci\\u00f3n que se desv\\u00ede a lo sumo un \\u00abepsilon\\u00bb de los datos reales para todos los puntos de entrenamiento, al mismo tiempo que es lo m\\u00e1s plana posible. Es efectiva en espacios de alta dimensi\\u00f3n y con conjuntos de datos complejos.\n",
        "\n",
        "*   **Árboles de Decisión para Regresión:** Aunque m\\u00e1s conocidos para clasificaci\\u00f3n, los \\u00e1rboles de decisi\\u00f3n tambi\\u00e9n se pueden usar para tareas de regresi\\u00f3n. Dividen el espacio de caracter\\u00edsticas en regiones y asignan un valor de predicci\\u00f3n (generalmente la media de los valores objetivo en esa regi\\u00f3n) a cada regi\\u00f3n.\n",
        "\n",
        "*   **Random Forest para Regresión:** Un m\\u00e9todo de conjunto que construye m\\u00faltiple \\u00e1rboles de decisi\\u00f3n para regresi\\u00f3n durante el entrenamiento y genera la predicci\\u00f3n promediando las predicciones de los \\u00e1rboles individuales. Ayuda a reducir el sobreajuste y mejorar la precisi\\u00f3n.\n",
        "\n",
        "*   **Gradient Boosting para Regresión (e.g., XGBoost, LightGBM):** Otro m\\u00e9todo de conjunto que construye modelos de forma secuencial, donde cada nuevo modelo corrige los errores de los modelos anteriores. Son extremadamente potentes y populares para problemas de regresi\\u00f3n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f239d92"
      },
      "source": [
        "### 3. Casos de Uso Comunes de los Modelos de Regresión\n",
        "\n",
        "Los modelos de regresión son herramientas versátiles que se aplican en una amplia variedad de dominios para predecir resultados continuos. Algunos de los casos de uso más comunes incluyen:\n",
        "\n",
        "*   **Predicción de Precios:** Uno de los usos más clásicos es predecir el precio de bienes como viviendas, acciones, vehículos usados o productos en el mercado, basándose en características relevantes (tamaño, ubicación, marca, etc.).\n",
        "\n",
        "*   **Pronóstico de Ventas:** Las empresas utilizan modelos de regresión para predecir las ventas futuras de productos o servicios, lo que ayuda en la planificación de inventarios, producción y estrategias de marketing. Los factores pueden incluir el gasto en publicidad, el precio del producto, las tendencias estacionales, etc.\n",
        "\n",
        "*   **Estimación de la Demanda:** Predecir la demanda de energía, agua, bienes de consumo o servicios. Esto es crucial para la gestión de recursos y la toma de decisiones operativas.\n",
        "\n",
        "*   **Análisis Financiero y Económico:** Predecir el crecimiento del PIB, la inflación, las tasas de interés, el rendimiento de las inversiones o el riesgo crediticio. Estos modelos ayudan a los economistas y analistas financieros a tomar decisiones informadas.\n",
        "\n",
        "*   **Medicina y Biología:** Estimar la dosis efectiva de un fármaco, predecir la duración de la estancia hospitalaria de un paciente, o modelar la relación entre factores genéticos y la expresión de una enfermedad.\n",
        "\n",
        "*   **Ciencias Ambientales:** Predecir niveles de contaminación, el impacto del cambio climático en la temperatura o el nivel del mar, o el rendimiento de cultivos basándose en condiciones meteorológicas.\n",
        "\n",
        "*   **Ingeniería:** Predecir la vida útil de un componente mecánico, el consumo de combustible de un vehículo o el rendimiento de materiales bajo diferentes condiciones de estrés.\n",
        "\n",
        "*   **Recursos Humanos:** Predecir el rendimiento de los empleados, el tiempo que tardará un nuevo empleado en adaptarse a un puesto o la rotación de personal, basándose en variables como la experiencia, la formación y el salario.\n",
        "\n",
        "Estos ejemplos demuestran cómo los modelos de regresión son fundamentales para obtener información valiosa y tomar decisiones basadas en datos en innumerables campos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e15c1a8"
      },
      "source": [
        "## Implementación y Evaluación de Modelos de Regresión\n",
        "\n",
        "### Subtask:\n",
        "Demostrar la implementación de un modelo de regresión usando Scikit-learn, incluyendo la carga de datos, preprocesamiento, entrenamiento del modelo y cálculo de métricas de evaluación de regresión.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a5d78cf"
      },
      "source": [
        "**Reasoning**:\n",
        "To demonstrate the implementation of a regression model, I will start by loading the California housing dataset, splitting it into training and testing sets, initializing and training a Linear Regression model, making predictions, and finally calculating and printing the specified evaluation metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7945696c",
        "outputId": "9d918e96-97e3-453d-f6bc-0051f9288b20"
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# 1. Importar y cargar el conjunto de datos de precios de viviendas de California\n",
        "housing = fetch_california_housing()\n",
        "X = housing.data\n",
        "y = housing.target\n",
        "\n",
        "print(\"Keys of housing_dataset:\\n{}\".format(housing.keys()))\n",
        "print(housing['DESCR'][:193] + \"\\n...\")\n",
        "\n",
        "# 2. Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"\\nTamaño del conjunto de entrenamiento (X_train): {X_train.shape}\")\n",
        "print(f\"Tamaño del conjunto de prueba (X_test): {X_test.shape}\")\n",
        "\n",
        "# 3. Inicializar un modelo de regresión lineal\n",
        "model = LinearRegression()\n",
        "\n",
        "# 4. Entrenar el modelo con los datos de entrenamiento\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Realizar predicciones sobre el conjunto de datos de prueba\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 6. Calcular e imprimir las métricas de evaluación\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nError Cuadrático Medio (MSE): {mse:.4f}\")\n",
        "print(f\"Error Absoluto Medio (MAE): {mae:.4f}\")\n",
        "print(f\"Coeficiente R-cuadrado (R2): {r2:.4f}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys of housing_dataset:\n",
            "dict_keys(['data', 'target', 'frame', 'target_names', 'feature_names', 'DESCR'])\n",
            ".. _california_housing_dataset:\n",
            "\n",
            "California Housing dataset\n",
            "--------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            ":Number of Instances: 20640\n",
            "\n",
            ":Number of Attributes: 8 numeric, predictive \n",
            "...\n",
            "\n",
            "Tamaño del conjunto de entrenamiento (X_train): (16512, 8)\n",
            "Tamaño del conjunto de prueba (X_test): (4128, 8)\n",
            "\n",
            "Error Cuadrático Medio (MSE): 0.5559\n",
            "Error Absoluto Medio (MAE): 0.5332\n",
            "Coeficiente R-cuadrado (R2): 0.5758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5514adf"
      },
      "source": [
        "## Comparación de Algoritmos y Métricas\n",
        "\n",
        "### Subtask:\n",
        "Discutir y comparar diferentes algoritmos de clasificación y regresión, así como las métricas clave utilizadas para evaluar su rendimiento. Se incluirá un ejemplo práctico donde se comparan múltiples modelos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e324043"
      },
      "source": [
        "### 1. La Importancia de Comparar Algoritmos y Métricas\n",
        "\n",
        "En el campo del aprendizaje automático, la elección del algoritmo correcto y la métrica de evaluación adecuada son pasos cruciales para construir un modelo predictivo robusto y eficaz. No existe un \"mejor\" algoritmo universal para todos los problemas; el rendimiento de un modelo depende en gran medida de la naturaleza de los datos, la complejidad de la relación entre las características y la variable objetivo, y los objetivos específicos del negocio o la investigación.\n",
        "\n",
        "Comparar diferentes algoritmos permite:\n",
        "\n",
        "*   **Identificar el modelo óptimo:** Cada algoritmo tiene sus fortalezas y debilidades. La comparación sistemática ayuda a descubrir cuál se adapta mejor a los patrones inherentes en un conjunto de datos particular.\n",
        "*   **Entender las limitaciones:** Al evaluar múltiples modelos, podemos comprender mejor dónde un algoritmo podría fallar o bajo qué condiciones su rendimiento podría degradarse.\n",
        "*   **Validar la robustez:** Un modelo que funciona bien con un solo algoritmo o un conjunto limitado de métricas podría no ser generalizable. Comparar con otros modelos y métricas proporciona una validación más completa de su capacidad para desempeñarse en datos no vistos.\n",
        "*   **Optimizar recursos:** Algunos algoritmos son más computacionalmente intensivos que otros. Comprender el equilibrio entre rendimiento y eficiencia computacional es vital, especialmente con grandes volúmenes de datos.\n",
        "\n",
        "Además, la elección de la **métrica de evaluación** es tan importante como la del algoritmo. Una métrica inapropiada puede llevar a conclusiones engañosas sobre el rendimiento del modelo. Por ejemplo, la precisión (accuracy) puede ser una métrica engañosa en conjuntos de datos desequilibrados, donde métricas como la precisión (precision), la exhaustividad (recall) o la puntuación F1 podrían ser más informativas. Para problemas de regresión, la elección entre el error absoluto medio (MAE) o el error cuadrático medio (MSE) depende de la sensibilidad deseada a los errores grandes.\n",
        "\n",
        "En esta sección, exploraremos una variedad de algoritmos y métricas para clasificación y regresión, y demostraremos cómo se pueden comparar en un escenario práctico para tomar decisiones informadas sobre la selección y optimización del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03b0d92e"
      },
      "source": [
        "### 2. Comparación de Algoritmos de Clasificación Comunes\n",
        "\n",
        "Los algoritmos de clasificación son herramientas fundamentales para predecir categorías discretas. A continuación, se comparan algunos de los más utilizados:\n",
        "\n",
        "*   **Regresión Logística (Logistic Regression):**\n",
        "    *   **Características:** A pesar de su nombre, es un algoritmo de clasificación. Modela la probabilidad de que una instancia pertenezca a una clase utilizando una función sigmoide. Es un modelo lineal simple y eficaz, especialmente para clasificación binaria, aunque puede extenderse a multiclase (multinomial logistic regression).\n",
        "    *   **Escenarios de Uso:** Detección de spam, predicción de enfermedades (sí/no), calificación crediticia. Es bueno para problemas donde se necesita la probabilidad de pertenencia a una clase y cuando los datos son linealmente separables o casi separables.\n",
        "    *   **Ventajas:** Rápido de entrenar, fácil de interpretar, robusto a la colinealidad (con regularización). Proporciona probabilidades de clase.\n",
        "    *   **Desventajas:** Asume una relación lineal entre las características y el log-odds de la probabilidad. Puede tener un bajo rendimiento con relaciones complejas o no lineales.\n",
        "\n",
        "*   **Árboles de Decisión (Decision Trees):**\n",
        "    *   **Características:** Un modelo no paramétrico que divide el espacio de características en regiones rectangulares y asigna una etiqueta de clase a cada región. Son intuitivos y fáciles de visualizar.\n",
        "    *   **Escenarios de Uso:** Diagnóstico médico, clasificación de clientes, sistemas de recomendación. Útil cuando la interpretabilidad del modelo es clave.\n",
        "    *   **Ventajas:** Fáciles de entender e interpretar, no requieren escalado de características, pueden manejar datos numéricos y categóricos. Pueden capturar interacciones no lineales complejas.\n",
        "    *   **Desventajas:** Propensos al sobreajuste (overfitting), pequeños cambios en los datos pueden llevar a un árbol muy diferente, suelen ser menos precisos que métodos de conjunto (ensemble methods).\n",
        "\n",
        "*   **K-Vecinos Más Cercanos (K-Nearest Neighbors - K-NN):**\n",
        "    *   **Características:** Un algoritmo de aprendizaje perezoso (lazy learning) y no paramétrico que clasifica una nueva instancia basándose en la mayoría de votos de sus 'k' vecinos más cercanos en el espacio de características. La distancia entre puntos es clave.\n",
        "    *   **Escenarios de Uso:** Sistemas de recomendación, reconocimiento de patrones, búsqueda de documentos similares. Funciona bien para conjuntos de datos pequeños o cuando la distribución de clases es irregular.\n",
        "    *   **Ventajas:** Simple de implementar, no hace suposiciones sobre la distribución de los datos, puede adaptarse bien a datos complejos.\n",
        "    *   **Desventajas:** Computacionalmente costoso para conjuntos de datos grandes (cada predicción requiere calcular distancias a todos los puntos de entrenamiento), sensible a la escala de las características y a los datos ruidosos o atípicos (outliers), el rendimiento depende en gran medida de la elección de 'k'.\n",
        "\n",
        "*   **Máquinas de Vectores de Soporte (Support Vector Machines - SVM):**\n",
        "    *   **Características:** Busca el hiperplano óptimo que mejor separe las clases en un espacio de características. Utiliza el \"truco del kernel\" para manejar datos no linealmente separables proyectándolos a un espacio de mayor dimensión.\n",
        "    *   **Escenarios de Uso:** Clasificación de texto, reconocimiento de imágenes, bioinformática. Efectivas en espacios de alta dimensión y cuando los datos no son linealmente separables.\n",
        "    *   **Ventajas:** Muy efectivo en espacios de alta dimensión, eficiente en memoria (solo utiliza los vectores de soporte), versátil con diferentes funciones de kernel.\n",
        "    *   **Desventajas:** Puede ser lento de entrenar en conjuntos de datos grandes, la elección del kernel y sus parámetros puede ser complicada, no proporciona probabilidades de clase directamente (aunque se puede estimar).\n",
        "\n",
        "*   **Bosques Aleatorios (Random Forest):**\n",
        "    *   **Características:** Un método de conjunto (ensemble) que construye múltiples árboles de decisión durante el entrenamiento y genera la predicción promediando las predicciones de los árboles individuales (o votando en clasificación). Reduce el sobreajuste y mejora la precisión en comparación con un solo árbol de decisión.\n",
        "    *   **Escenarios de Uso:** Detección de fraude, modelado predictivo en finanzas, diagnóstico médico. Es un algoritmo de propósito general muy potente.\n",
        "    *   **Ventajas:** Alta precisión, robusto al sobreajuste, puede manejar miles de variables de entrada sin selección de características, puede trabajar con datos faltantes, proporciona estimaciones de importancia de características.\n",
        "    *   **Desventajas:** Menos interpretable que un solo árbol de decisión, puede ser computacionalmente intensivo y consumir mucha memoria cuando se construye con muchos árboles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7ab2b3a"
      },
      "source": [
        "### 3. Métricas de Evaluación de Clasificación Comunes\n",
        "\n",
        "La elección de la métrica de evaluación es crucial para entender el rendimiento de un modelo de clasificación, especialmente en escenarios con clases desequilibradas o con diferentes costos asociados a los errores. A continuación, se detallan las métricas más comunes:\n",
        "\n",
        "*   **Precisión (Accuracy):**\n",
        "    *   **Definición:** Es la proporción de predicciones correctas sobre el total de predicciones. Se calcula como `(True Positives + True Negatives) / Total de Instancias`.\n",
        "    *   **Cuándo Usarla:** Útil cuando las clases están bien balanceadas y el costo de los falsos positivos y falsos negativos es similar. Es la métrica más intuitiva y fácil de entender.\n",
        "    *   **Limitaciones:** Puede ser engañosa en conjuntos de datos desequilibrados. Por ejemplo, en un problema con un 95% de una clase y un 5% de la otra, un modelo que siempre predice la clase mayoritaria tendrá un 95% de precisión, pero sería inútil para la clase minoritaria.\n",
        "\n",
        "*   **Matriz de Confusión (Confusion Matrix):**\n",
        "    *   **Definición:** Es una tabla que muestra el número de verdaderos positivos (TP), verdaderos negativos (TN), falsos positivos (FP) y falsos negativos (FN). Es la base para calcular muchas otras métricas.\n",
        "    *   **Componentes Clave:**\n",
        "        *   **Verdaderos Positivos (TP):** Instancias positivas predichas correctamente como positivas.\n",
        "        *   **Verdaderos Negativos (TN):** Instancias negativas predichas correctamente como negativas.\n",
        "        *   **Falsos Positivos (FP):** Instancias negativas predichas incorrectamente como positivas (error de Tipo I).\n",
        "        *   **Falsos Negativos (FN):** Instancias positivas predichas incorrectamente como negativas (error de Tipo II).\n",
        "    *   **Cuándo Usarla:** Siempre. Es el punto de partida para una evaluación detallada, ya que proporciona una visión completa de los tipos de errores que comete el modelo.\n",
        "\n",
        "*   **Precisión (Precision):**\n",
        "    *   **Definición:** Proporción de predicciones positivas que fueron realmente correctas. Se calcula como `TP / (TP + FP)`.\n",
        "    *   **Cuándo Usarla:** Cuando el costo de un falso positivo es alto. Por ejemplo, en la detección de spam, si un correo legítimo se clasifica como spam (FP), el usuario podría perder información importante. En este caso, queremos un modelo con alta precisión para minimizar los FP.\n",
        "\n",
        "*   **Exhaustividad o Sensibilidad (Recall / Sensitivity):**\n",
        "    *   **Definición:** Proporción de instancias positivas reales que fueron identificadas correctamente. Se calcula como `TP / (TP + FN)`.\n",
        "    *   **Cuándo Usarla:** Cuando el costo de un falso negativo es alto. Por ejemplo, en el diagnóstico médico para detectar una enfermedad grave, si un paciente enfermo se clasifica como sano (FN), podría no recibir el tratamiento necesario. En este caso, queremos un modelo con alta exhaustividad para minimizar los FN.\n",
        "\n",
        "*   **Puntuación F1 (F1-Score):**\n",
        "    *   **Definición:** Es la media armónica de la Precisión y la Exhaustividad. Se calcula como `2 * (Precision * Recall) / (Precision + Recall)`.\n",
        "    *   **Cuándo Usarla:** Cuando se necesita un equilibrio entre Precisión y Exhaustividad, especialmente en problemas con clases desequilibradas. Es una buena métrica para tener una visión general del rendimiento cuando ambos tipos de errores (FP y FN) son importantes.\n",
        "\n",
        "*   **Curva ROC y AUC (Receiver Operating Characteristic & Area Under the Curve):**\n",
        "    *   **Definición:** La curva ROC grafica la tasa de verdaderos positivos (TPR, que es Recall) contra la tasa de falsos positivos (FPR) en varios umbrales de clasificación. El AUC es el área bajo esta curva.\n",
        "    *   **Cuándo Usarla:** Para evaluar el rendimiento general de un clasificador en diferentes umbrales, especialmente en problemas de clasificación binaria y con clases desequilibradas. Un AUC alto (cercano a 1) indica que el modelo es capaz de distinguir bien entre las clases. Un AUC de 0.5 sugiere que el modelo no es mejor que una clasificación aleatoria.\n",
        "\n",
        "La elección de la métrica o conjunto de métricas dependerá directamente de los objetivos del problema y de las consecuencias de los diferentes tipos de errores en el contexto real."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b8f1a18"
      },
      "source": [
        "### 4. Comparación de Algoritmos de Regresión Comunes\n",
        "\n",
        "Los algoritmos de regresión tienen como objetivo predecir un valor continuo o numérico. A continuación, se comparan algunos de los más utilizados:\n",
        "\n",
        "*   **Regresión Lineal (Linear Regression):**\n",
        "    *   **Característica:** Es el modelo de regresión más básico. Asume una relación lineal entre las variables independientes y la variable dependiente. Su objetivo es encontrar la línea (o hiperplano) que mejor se ajuste a los datos, minimizando la suma de los cuadrados de los errores (MSE).\n",
        "    *   **Escenarios de Uso:** Predicción de precios de viviendas, pronóstico de ventas, modelado de relaciones simples entre variables. Es un buen punto de partida para muchos problemas de regresión.\n",
        "    *   **Ventajas:** Simple, rápido de entrenar, fácil de interpretar. Sirve como un buen modelo de referencia (baseline).\n",
        "    *   **Desventajas:** Asume linealidad, lo que rara vez ocurre en el mundo real. Sensible a valores atípicos (outliers) y a la multicolinealidad entre las características.\n",
        "\n",
        "*   **Regresión Ridge (Ridge Regression):**\n",
        "    *   **Característica:** Una extensión de la regresión lineal que añade un término de regularización L2 a la función de costo. Esto penaliza los coeficientes grandes, reduciendo el sobreajuste y mejorando la generalización, especialmente cuando hay muchas características correlacionadas.\n",
        "    *   **Escenarios de Uso:** Problemas con un gran número de características, o cuando existe multicolinealidad. Útil para la predicción de precios o el análisis financiero donde se manejan muchos factores.\n",
        "    *   **Ventajas:** Reduce el sobreajuste, maneja la multicolinealidad mejor que la regresión lineal simple, tiende a incluir todas las características en el modelo pero con pesos reducidos.\n",
        "    *   **Desventajas:** No realiza selección de características; los coeficientes nunca se reducen exactamente a cero.\n",
        "\n",
        "*   **Regresión Lasso (Lasso Regression):**\n",
        "    *   **Característica:** Otra extensión de la regresión lineal que añade un término de regularización L1 a la función de costo. A diferencia de Ridge, Lasso puede reducir los coeficientes de algunas características exactamente a cero, realizando efectivamente una selección de características.\n",
        "    *   **Escenarios de Uso:** Cuando se desea la selección automática de características y se sospecha que muchas de ellas son irrelevantes. Muy útil en genética, procesamiento de señales y finanzas.\n",
        "    *   **Ventajas:** Realiza selección de características, reduce el sobreajuste, puede construir modelos más interpretables.\n",
        "    *   **Desventajas:** Puede tener un rendimiento inestable cuando hay grupos de características altamente correlacionadas (tiende a seleccionar una y descartar las otras), puede no ser la mejor opción cuando se espera que todas las características sean importantes.\n",
        "\n",
        "*   **Árboles de Decisión para Regresión (Decision Trees for Regression):**\n",
        "    *   **Característica:** Similar a los árboles de decisión para clasificación, pero en lugar de predecir una clase, predice un valor numérico continuo para cada hoja del árbol (generalmente la media de los valores objetivo de las instancias en esa hoja).\n",
        "    *   **Escenarios de Uso:** Problemas con relaciones no lineales complejas entre las características y el objetivo, donde la interpretabilidad del modelo es importante. Predicción del rendimiento de cultivos, estimación de la duración de proyectos.\n",
        "    *   **Ventajas:** Fáciles de entender e interpretar, pueden capturar interacciones no lineales, no requieren escalado de características.\n",
        "    *   **Desventajas:** Propensos al sobreajuste si no se podan o limitan adecuadamente, inestables (pequeños cambios en los datos pueden afectar drásticamente la estructura del árbol).\n",
        "\n",
        "*   **Random Forest para Regresión (Random Forest for Regression):**\n",
        "    *   **Característica:** Un método de conjunto que construye múltiples árboles de decisión para regresión durante el entrenamiento. La predicción final se obtiene promediando las predicciones de todos los árboles individuales. Mitiga el sobreajuste de los árboles de decisión individuales.\n",
        "    *   **Escenarios de Uso:** Predicción de precios de activos, pronóstico de la demanda, modelado de riesgos. Es uno de los algoritmos de regresión más potentes y de propósito general.\n",
        "    *   **Ventajas:** Alta precisión, robusto al sobreajuste, maneja bien las interacciones no lineales, menos sensible al ruido en los datos, proporciona importancia de características.\n",
        "    *   **Desventajas:** Menos interpretable que un solo árbol de decisión, puede ser computacionalmente intensivo para conjuntos de datos muy grandes o con muchos árboles, requiere más memoria."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4168cbff"
      },
      "source": [
        "### 5. Métricas de Evaluación de Regresión Comunes\n",
        "\n",
        "Las métricas de evaluación de regresión se utilizan para cuantificar la diferencia entre los valores predichos por el modelo y los valores reales. A continuación, se detallan las métricas más comunes:\n",
        "\n",
        "*   **Error Absoluto Medio (Mean Absolute Error - MAE):**\n",
        "    *   **Definición:** Es el promedio de los valores absolutos de los errores (la diferencia entre la predicción y el valor real). `MAE = (1/n) * Σ |y_real - y_pred|`\n",
        "    *   **Cuándo Usarla:** Es una métrica robusta a los valores atípicos (outliers) ya que no los penaliza tan severamente como el MSE. Es fácil de interpretar porque está en las mismas unidades que la variable objetivo.\n",
        "    *   **Limitaciones:** No indica la dirección de los errores (si el modelo subestima o sobreestima consistentemente). No diferencia entre errores pequeños y grandes de la misma manera que el MSE.\n",
        "\n",
        "*   **Error Cuadrático Medio (Mean Squared Error - MSE):**\n",
        "    *   **Definición:** Es el promedio de los cuadrados de los errores. `MSE = (1/n) * Σ (y_real - y_pred)^2`\n",
        "    *   **Cuándo Usarla:** Es una de las métricas más comunes y penaliza fuertemente los errores grandes debido al término cuadrático. Esto la hace útil cuando los errores grandes son particularmente indeseables.\n",
        "    *   **Limitaciones:** Su resultado está en unidades cuadráticas de la variable objetivo, lo que puede dificultar la interpretación directa. Es muy sensible a los valores atípicos.\n",
        "\n",
        "*   **Raíz del Error Cuadrático Medio (Root Mean Squared Error - RMSE):**\n",
        "    *   **Definición:** Es la raíz cuadrada del MSE. `RMSE = √MSE`\n",
        "    *   **Cuándo Usarla:** Resuelve el problema de la interpretabilidad del MSE al devolver la métrica a las mismas unidades que la variable objetivo. Al igual que el MSE, penaliza los errores grandes, pero es más fácil de entender en términos de la magnitud del error promedio.\n",
        "    *   **Limitaciones:** Sigue siendo sensible a los valores atípicos.\n",
        "\n",
        "*   **R-cuadrado (R-squared o Coeficiente de Determinación):**\n",
        "    *   **Definición:** Mide la proporción de la varianza en la variable dependiente que es predecible a partir de las variables independientes. Un valor de 1.0 indica que el modelo explica toda la variabilidad de la variable objetivo, mientras que un valor de 0.0 indica que el modelo no explica ninguna variabilidad.\n",
        "    *   **Cuándo Usarla:** Para entender qué tan bien las características explican la variabilidad de la variable objetivo. Es útil para la comparación entre modelos que predicen la misma variable objetivo en el mismo conjunto de datos.\n",
        "    *   **Limitaciones:** No indica si las predicciones son sesgadas (si el modelo predice consistentemente valores más altos o más bajos). Puede aumentar artificialmente al añadir más variables predictoras, incluso si no son significativas. Para abordar esto, a menudo se usa el **R-cuadrado ajustado** (Adjusted R-squared).\n",
        "\n",
        "La elección de la métrica de regresión depende del contexto del problema, la distribución de los errores y la importancia relativa de los errores grandes versus pequeños."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8124a94"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to implement a practical example comparing at least two classification models using the Iris dataset, as specified in the instructions. This involves loading the dataset, splitting it, training different models, making predictions, and evaluating them using various metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50baab4b",
        "outputId": "f920c0e6-623b-4ea4-81c9-d45095fbb0dd"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "# 6. Implementar un ejemplo práctico para comparar modelos de clasificación\n",
        "\n",
        "# a. Cargar el conjunto de datos Iris\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "print(\"Comparación de Modelos de Clasificación en el Conjunto de Datos Iris\\n\")\n",
        "\n",
        "# --- Modelo 1: Regresión Logística ---\n",
        "print(\"### Modelo: Regresión Logística\")\n",
        "\n",
        "# b. Inicializar y entrenar el modelo\n",
        "logistic_model = LogisticRegression(random_state=42, max_iter=200, solver='liblinear')\n",
        "logistic_model.fit(X_train, y_train)\n",
        "\n",
        "# c. Realizar predicciones sobre el conjunto de prueba\n",
        "y_pred_logistic = logistic_model.predict(X_test)\n",
        "\n",
        "# d. Calcular e imprimir métricas\n",
        "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
        "print(f\"Precisión (Accuracy): {accuracy_logistic:.4f}\")\n",
        "print(\"Informe de Clasificación:\\n\", classification_report(y_test, y_pred_logistic, target_names=iris.target_names))\n",
        "print(\"Matriz de Confusión:\\n\", confusion_matrix(y_test, y_pred_logistic))\n",
        "\n",
        "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "# --- Modelo 2: Árbol de Decisión ---\n",
        "print(\"### Modelo: Árbol de Decisión\")\n",
        "\n",
        "# b. Inicializar y entrenar el modelo\n",
        "decision_tree_model = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree_model.fit(X_train, y_train)\n",
        "\n",
        "# c. Realizar predicciones sobre el conjunto de prueba\n",
        "y_pred_tree = decision_tree_model.predict(X_test)\n",
        "\n",
        "# d. Calcular e imprimir métricas\n",
        "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
        "print(f\"Precisión (Accuracy): {accuracy_tree:.4f}\")\n",
        "print(\"Informe de Clasificación:\\n\", classification_report(y_test, y_pred_tree, target_names=iris.target_names))\n",
        "print(\"Matriz de Confusión:\\n\", confusion_matrix(y_test, y_pred_tree))\n",
        "\n",
        "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "# e. Presentar los resultados de manera clara para facilitar la comparación\n",
        "results = pd.DataFrame({\n",
        "    'Modelo': ['Regresión Logística', 'Árbol de Decisión'],\n",
        "    'Precisión (Accuracy)': [accuracy_logistic, accuracy_tree]\n",
        "})\n",
        "print(\"Resumen de Precisión de los Modelos:\\n\")\n",
        "print(results.to_markdown(index=False))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparación de Modelos de Clasificación en el Conjunto de Datos Iris\n",
            "\n",
            "### Modelo: Regresión Logística\n",
            "Precisión (Accuracy): 0.9111\n",
            "Informe de Clasificación:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        15\n",
            "  versicolor       1.00      0.73      0.85        15\n",
            "   virginica       0.79      1.00      0.88        15\n",
            "\n",
            "    accuracy                           0.91        45\n",
            "   macro avg       0.93      0.91      0.91        45\n",
            "weighted avg       0.93      0.91      0.91        45\n",
            "\n",
            "Matriz de Confusión:\n",
            " [[15  0  0]\n",
            " [ 0 11  4]\n",
            " [ 0  0 15]]\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "### Modelo: Árbol de Decisión\n",
            "Precisión (Accuracy): 0.9333\n",
            "Informe de Clasificación:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        15\n",
            "  versicolor       1.00      0.80      0.89        15\n",
            "   virginica       0.83      1.00      0.91        15\n",
            "\n",
            "    accuracy                           0.93        45\n",
            "   macro avg       0.94      0.93      0.93        45\n",
            "weighted avg       0.94      0.93      0.93        45\n",
            "\n",
            "Matriz de Confusión:\n",
            " [[15  0  0]\n",
            " [ 0 12  3]\n",
            " [ 0  0 15]]\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Resumen de Precisión de los Modelos:\n",
            "\n",
            "| Modelo              |   Precisión (Accuracy) |\n",
            "|:--------------------|-----------------------:|\n",
            "| Regresión Logística |               0.911111 |\n",
            "| Árbol de Decisión   |               0.933333 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "683893f3"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Resumir los conceptos clave aprendidos y ofrecer una guía sobre cómo elegir el modelo y las métricas de evaluación adecuadas para diferentes problemas de aprendizaje automático.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6f3d1c8"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Classification Models Fundamentals**: The process successfully defined classification models, distinguishing them from regression, and detailed common types such as Binary, Multiclass, and Multilabel classification, alongside practical use cases like spam detection and medical diagnosis.\n",
        "*   **Regression Models Fundamentals**: The process provided a comprehensive explanation of regression models, emphasizing their role in predicting continuous values, and outlined various types including Linear, Polynomial, Regularized (Ridge, Lasso), Support Vector, and Tree-based regression models, with common applications like price prediction and sales forecasting.\n",
        "*   **Practical Classification Implementation**: A Logistic Regression model was successfully implemented using Scikit-learn on the Iris dataset, demonstrating data loading, splitting (105 training, 45 testing samples), training, and prediction, achieving a perfect accuracy of 1.0000 on the test set.\n",
        "*   **Practical Regression Implementation**: A Linear Regression model was successfully implemented on the California housing dataset, involving data loading, splitting (16512 training, 4128 testing samples), training, and prediction. The model achieved an **Error Cuadrático Medio (MSE) of 0.5559**, an **Error Absoluto Medio (MAE) of 0.5332**, and an **R-cuadrado (R2) of 0.5758**, indicating that it explains approximately 57.58% of the variance in housing prices.\n",
        "*   **Algorithm and Metric Comparison**: Detailed comparisons for both classification and regression algorithms (e.g., Logistic Regression vs. Decision Tree, Linear Regression vs. Ridge/Lasso) were provided. Key evaluation metrics for classification (Accuracy, Precision, Recall, F1-Score, ROC/AUC) and regression (MAE, MSE, RMSE, R-squared) were also explained.\n",
        "*   **Comparative Classification Example**: A practical comparison between Logistic Regression and Decision Tree Classifier on the Iris dataset showed that the Decision Tree model (accuracy: 0.9333) slightly outperformed Logistic Regression (accuracy: 0.9111) for this specific dataset split, with fewer misclassifications in the 'versicolor' class.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The tutorial provides a strong foundational understanding and practical examples of both classification and regression, which are crucial for beginners in machine learning.\n",
        "*   For future iterations, incorporating advanced preprocessing techniques (e.g., scaling, one-hot encoding), hyperparameter tuning, and cross-validation for more robust model evaluation would enhance the comprehensiveness of the tutorial.\n"
      ]
    }
  ]
}